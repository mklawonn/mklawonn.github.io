<!doctype html>
<html lang="en">

	<head>
		<meta charset="utf-8">

		<title>Intro to Deep Learning</title>

		<meta name="description" content="A framework for easily creating beautiful presentations using HTML">
		<meta name="author" content="Hakim El Hattab">

		<meta name="apple-mobile-web-app-capable" content="yes">
		<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/serif.css" id="theme">

		<!-- Theme used for syntax highlighting of code -->
		<link rel="stylesheet" href="lib/css/zenburn.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>

		<!--[if lt IE 9]>
		<script src="lib/js/html5shiv.js"></script>
		<![endif]-->
	</head>

	<body>

		<div class="reveal">

                <!-- Any section element inside of this container is displayed as a slide -->
                <div class="slides">

                <section>
                    <h2>Introduction to Deep Learning</h2>
                    <h5>Matt Klawonn</h5>
                </section>

                <!-- Deep Learning Demonstrations Nest -->
                <section>
                    <section>
                        <h2>Demonstrations</h2>
                        <ul>
                            <li>Image Classification</li>
                            <li>Sentiment Analysis</li>
                            <li>Visual Question Answering</li>
                        <ul>
                    </section>

                    <section>
                        <h2>Image Classification</h2>
                        <iframe style="height:600px;width:900px" src="http://demo.caffe.berkeleyvision.org/"></iframe>
                        <p><small><a href="http://demo.caffe.berkeleyvision.org/">Caffe Demo</a></small></p>
                    </section>

                    <section>
                        <h2>Sentiment Analysis</h2>
                        <iframe style="height:600px;width:900px" src="http://nlp.stanford.edu:8080/sentiment/rntnDemo.html"></iframe>
                        <p><small><a href="http://nlp.stanford.edu:8080/sentiment/rntnDemo.html">Stanford NLP Sentiment Analysis</a></small></p>
                    </section>

                    <section>
                        <h2>Visual Question Answering</h2>
                        <iframe style="height:600px;width:900px" src="http://visualqa.csail.mit.edu/"></iframe>
                        <p><small><a href="http://visualqa.csail.mit.edu/">MIT Visual Question Answering</a></small></p>
                    </section>
                </section>

                <!-- Talk Overview -->
                <section>
                    <h2>Deep Learning</h2>
                    <ul>
                        <li>What is it?</li>
                        <li>Why use it?</li>
                        <li>How to use it?</li>
                        <li>Where to start?</li>
                        <li>Coding Demo</li>
                    </ul>
                </section>

                <!-- What is Deep Learning Nest -->
                <section>
                    <section>
                        <h2>Talk Overview</h2>
                        <ul style="color:#d3d3d3">
                            <li style="color:#333">What is it?</li>
                            <li>Why use it?</li>
                            <li>How to use it?</li>
                            <li>Where to start?</li>
                            <li>Coding Demo</li>
                        </ul>
                    </section>
                    <!-- Brief ML Reminder -->
                    <section>
                        <h2>The Machine Learning Task</h2>
                        <img src="images/machine_learning_problem.png"/>
                        <p><small>Image courtesy of <a href="http://121.42.47.99/yuenshome/wordpress/?p=2383">here</a></small></p>
                    </section>

                    <section>
                        <h2>Traditional Approach</h2>
                        <div style="position:relative; width:640px; height:410px; margin:0 auto;">
                            <img src="images/machine_learning_features.jpg" height="400" style="position:absolute;top:0;left:50%;margin-left:-255px;"/>
                            <!-- Altered version with boxes outlining that the features are hand crafted -->
                            <img class="fragment" src="images/ML_Features.png" height="400" style="position:absolute;top:0;left:50%;margin-left:-255px;"/>
                        </div>
                        <p><small>Image courtesy of <a href="http://www.slideshare.net/rahuldausa/introduction-to-machine-learning-38791937">here</a></small></p>
                    </section>

                    <section>
                        <h2>Deep Learning Approach</h2>
                        <div style="position:relative; width:640px; height:410px; margin:0 auto;">
                            <img src="images/deep_learning_learn_features.jpg" height="400" style="position:absolute;top:0;left:50%;margin-left:-305px;"/>
                            <!-- Altered version with boxes outlining that the features are learned -->
                            <img class="fragment" src="images/DL_Features.png" height="400" style="position:absolute;top:0;left:50%;margin-left:-305px;"/>
                        </div>
                        <p><small>Image courtesy of <a href="http://www.slideshare.net/roelofp/python-for-image-understanding-deep-learning-with-convolutional-neural-nets">here</a></small></p>
                    </section>

                    <section>
                        <h2>Neural Networks</h2>
                        <p>Neural networks are machine learning models which rely on "neurons," or "units" to compute a function. <span class="fragment">They learn to approximate a function by intelligently updating the weights of connections between neurons.</span></p>
                    </section>

                    <section>
                        <p><img src="images/deep_learning_learn_features.jpg"/></p>
                        <aside class="notes">Here we have a multilayer neural network model. The data is passed in to the model via the input layer, while the output layer computes the desired function. In this diagram there is one output unit, so this model is likely intended to predict a single value. The computation is performed by the hidden layers, where each unit in the layers performs a nonlinear transformation over the weighted sum of its inputs. Learning is done by updating the weights between neurons.</aside>
                    </section>

                    <section>
                        <p><img src="images/backpropagation.png"/></p>
                        <p><small>Illustration of backpropagation. Image courtesy of <a href="http://www.kdnuggets.com/2016/06/visual-explanation-backpropagation-algorithm-neural-networks.html">here</a></small></p>
                    </section>

                    <section>
                        <iframe width="640" height="480" src="https://www.youtube.com/embed/nrnxZVEHZCo" frameborder="0" allowfullscreen></iframe>
                    </section>

                </section>

                <!-- Why Deep Learning -->
                <section>
                    <section>
                        <h2>Talk Overview</h2>
                        <ul style="color:#d3d3d3">
                            <li>What is it?</li>
                            <li style="color:#333">Why use it?</li>
                            <li>How to use it?</li>
                            <li>Where to start?</li>
                            <li>Coding Demo</li>
                        </ul>
                    </section>
                    <!-- Brief History (ANNs)-->
                    <!-- Make sure to mention the crazy expressiveness -->
                    <section>
                        <h2>Artificial Neural Networks</h2>
                        <h3>A Brief Incomplete History</h3>
                        <ul>
                            <li class="fragment">1961: Multilayer Perceptron</li>
                            <li class="fragment">1985: Backpropagation</li>
                            <li class="fragment">1988: Convolutional Neural Networks</li>
                            <li class="fragment">1998: LeNet</li>
                            <li class="fragment">2006: Layerwise pre-training</li>
                        </ul>
                    </section>
                    <!-- Why it didn't work -->
                    <section>
                        <h2>Why It Didn't Work</h2>
                        <p>Overfitting</p>
                        <img src="images/goodfit_overfitting.png" />
                        <p><small>Example of overfitting. Image courtesy of <a href="http://blog.fliptop.com/blog/2015/03/02/bias-variance-and-overfitting-machine-learning-overview/">here</a></small></p>
                    </section>

                    <section>
                        <h2>Why It Didn't Work</h2>
                        <p>Theoretical Training Difficulties</p>
                        <img src="images/vanishing_gradient.jpg" />
                        <p class="fragment">The vanishing gradient problem is one training difficulty.</p>
                        <p><small>Vanishing gradient illustration. Image courtesy of <a href="http://www.slideshare.net/Eniod/deep-learning-and-business-models-vnitc-20150913">here</a></small></p>
                    </section>

                    <section>
                        <h2>Why It Didn't Work</h2>
                        <p>Practical Training Difficulties</p>
                        <img src="images/crt_monitor.jpg" height=400px/>
                        <p class="fragment">Old machines were insufficient to realistically train deep nets.</p>
                        <p><small>Image courtesy of <a href="http://www.recycledgoods.com/monitors/page/20/">here</a></small></p>
                    </section>

                    <!-- What Changed -->  
                    <section>
                        <h2>What Changed?</h2>
                        <ul>
                            <li class="fragment">Improved Regularization</li>
                            <li class="fragment">Tricks to Preserve Signals</li>
                            <li class="fragment">Big Data</li>
                            <li class="fragment">Beefy Machines</li>
                        </ul>
                    </section>
                    <!-- Theoretical efficiency of deep architectures -->
                    <section>
                        <h2>Why Deep Architectures?</h2>
                        <div class="fragment">
                            <h5>Efficiency!</h5>
                            <p><img src="images/inneficient_shallow_architecture.png"/></p>
                            <p><small>Example of gaussian process inefficiency</small></p>
                            <p>See <a href="#/8/1">[1]</a></p>
                        </div>
                    </section>
                    <!-- Is deep learning appropriate for my task? -->
                    <section>
                        <h2>Deep Learning and You</h2>
                        <ul>
                            <li class="fragment">Lots of data?</li>
                            <li class="fragment">Big machines?</li>
                            <li class="fragment">Limited problem insight?</li>
                            <li class="fragment">Deep learning is for you</li>
                        </ul>
                    </section>

                    <!-- Why Deep Learning Sucks -->
                    <!-- Little to no theory -->
                    <!-- Lots of tricks -->
                    <!-- "Do stuff cause it works" -->
                    <!-- Is it actually working? Beating datasets to death -->
                    <section>
                        <h2>Complaints</h2>
                        <p>There's very little in the way of deep learning theory beyond the basics. <span class="fragment">As such, practitioners tend to rely on a number of "tricks."</span></p>
                    </section>

                    <section>
                        <h2>"Because it works"</h2>
                        <p><img src="images/resnet_2.png" /></p>
                        <p><small>Residual network proposed by Microsoft. Image courtesy of <a href="#/8/1">[2]</a></small></p>
                        <aside class="notes">Residual networks were proposed. Residual networks simply involve taking as input the output from two layers ago. When asked why that number two was chosen, the speaker responded "because 1 and 3 didn't work."</aside>
                    </section>

                    <section>
                        <h2>Does it actually work?</h2>
                        <p><img src="images/adversarial_panda.png" /></p>
                        <p><small>Example of adversarial problem. Image courtesy of <a href="http://www.kdnuggets.com/2015/07/deep-learning-adversarial-examples-misconceptions.html">here</a></small></p>
                    </section>

                    <section>
                        <h2>Does it actually work?</h2>
                        <p><img src="images/understanding-deep-learning-fig-1.jpeg" /></p>
                        <p><small>Example of overfitting. Image courtesy of [5]</small></p>
                    </section>
                </section>

                <!-- Tricks of the Trade -->
                <section>
                    <section>
                        <h2>Talk Overview</h2>
                        <ul style="color:#d3d3d3">
                            <li>What is it?</li>
                            <li>Why use it?</li>
                            <li style="color:#333">How to use it?</li>
                            <li>Where to start?</li>
                            <li>Coding Demo</li>
                        </ul>
                    </section>

                    <section>
                        <h2>Early Stopping</h2>
                        <p>Stop when validation loss stops decreasing.</p>
                        <p><img src="images/earlystopping.jpg" height=400px /></p>
                        <p><small>Early stopping illustration. Image courtesy of <a href="https://visualstudiomagazine.com/articles/2015/05/01/train-validate-test-stopping.aspx">here</a></small></p>
                    </section>

                    <section>
                        <h2>Hyperparameter Choices</h2>
                        <p>Neural Networks are used in conjunction with non-convex losses, so hyperparameters matter!</p>
                        <p><img src="images/nonconvex-cost.png" /></p>
                        <p><small>Example non-convex cost function. Image courtesy of <a href="http://sebastianraschka.com/faq/docs/visual-backpropagation.html">here</a></small></p>
                    </section>

                    <section>
                        <h2>Data Augmentation and Preprocessing</h2>
                        <p><img src="images/augmentation.svg" height=400px /></p>
                        <p><small>Example of generating image for data augmentation. Image courtesy of <a href="https://matthewearl.github.io/2016/05/06/cnn-anpr/">here</a></small></p>
                    </section>

                    <section>
                        <h2>Regularization</h2>
                        <p><img src="images/dropout1.png" /></p>
                        <p><small>Dropout illustration. Image courtesy of <a href="http://everglory99.github.io/Intro_DL_TCC/#/">here</a></small></p>
                    </section>

                    <section>
                        <h2>Reuse Models</h2>
                        <p><img src="images/model_reuse.jpg" /></p>
                        <p><small>Example of model reuse. Image courtesy of <a href="http://www.slideshare.net/xavigiro/deepfix-a-fully-convolutional-neural-network-for-predicting-human-fixations">here</a></small></p>
                    </section>

                </section>

                <!-- Where to start -->
                <section>
                    <section>
                        <h2>Talk Overview</h2>
                        <ul style="color:#d3d3d3">
                            <li>What is it?</li>
                            <li>Why use it?</li>
                            <li>How to use it?</li>
                            <li style="color:#333">Where to start?</li>
                            <li>Coding Demo</li>
                        </ul>
                    </section>

                    <!-- Frameworks -->
                    <section>
                        <h2>Lots of Frameworks</h2>
                        <ul>
                            <li><a href="http://deeplearning.net/software/theano/">Theano</a></li>
                            <li><a href="http://torch.ch/">Torch</a></li>
                            <li><a href="https://www.tensorflow.org/">Tensorflow</a></li>
                            <li><a href="http://lasagne.readthedocs.io/en/latest/user/installation.html">Lasagne</a></li>
                            <li><a href="http://caffe.berkeleyvision.org/">Caffe</a></li>
                            <li><a href="https://keras.io/">Keras</a></li>
                        </ul>
                        <aside class="notes">Listed from low level to high level.</aside>
                    </section>

                    <section>
                        <h2>Tutorials</h2>
                        <ul>
                            <li><a href="https://github.com/Vict0rSch/deep_learning">Lasagne and Keras</a></li>
                            <li><a href="http://neuralnetworksanddeeplearning.com/chap1.html">General Deep Learning</a></li>
                            <li><a href="http://deeplearning.net/tutorial/">Theano</a></li>
                        </ul>
                    </section>

                    <section>
                        <h2>Data</h2>
                        <ul>
                            <li><a href="http://yann.lecun.com/exdb/mnist/">MNIST</a></li>
                            <li><a href="http://image-net.org/">ImageNet</a></li>
                            <li><a href="http://www.visualqa.org/">VQA</a></li>
                            <li><a href="http://www.statmt.org/wmt15/translation-task.html">Machine Translation</a></li>
                            <li><a href="https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews">Sentiment Analysis</a></li>
                        </ul>
                    </section>
                </section>


                <!-- Let's live code an example -->
                <section>
                    <section>
                        <h2>Talk Overview</h2>
                        <ul style="color:#d3d3d3">
                            <li>What is it?</li>
                            <li>Why use it?</li>
                            <li>How to use it?</li>
                            <li>Where to start?</li>
                            <li style="color:#333">Coding Demo</li>
                        </ul>
                    </section>

                    <section>
                        <h2>Keras MNIST CNN</h2>
                        <p>We will classify data from MNIST (handwritten digits) using Keras. <span class="fragment">To do this, we will construct a convolutional neural network.</span></p>
                        <p><small>All code from <a href="https://github.com/fchollet/keras/blob/master/examples/mnist_cnn.py">keras examples.</a></small></p>
                    </section>

                    <section>
                        <h2>Machinery Needed: CNNs</h2>
                        <p>Convolutional Neural Networks exploit spatially-local correlation in images to automatically extract features relevant to the task at hand. <span class="fragment">Let's look at an example.</span></p>
                        <p><img src="images/mylenet.png" /></p>
                        <p><small>LeNet CNN architecture. Image courtesy of <a href="http://deeplearning.net/tutorial/lenet.html">here</a></small></p>
                        <aside class="notes">They compute convolutions of an image by repeatedly applying filters across sub-regions of an image.</aside>
                    </section>

                    <section>
                        <iframe src="https://cs231n.github.io/assets/conv-demo/index.html" width="100%" height="700px;" style="border:none;"></iframe>
                        <p><small>Animation courtesy of <a href="https://cs231n.github.io/assets/conv-demo/index.html">here</a></small></p>
                        <aside class="notes">Here we can see the filter being performed across windows of the image. These are aggregated into feature maps, which represent various features automatically extracted from the image. One reason CNNs are so successful is that these filters are learned and tuned for the task at hand, which corresponds to learning good features for the problem.</aside>
                    </section>

                    <section>
                        <h2>Preparing The Data</h2>
                        <pre><code class="python" data-trim contenteditable>
from keras.datasets import mnist
from keras.utils import np_utils
(X_train, y_train), (X_test, y_test) = mnist.load_data()
X_train = X_train.astype('float32')
X_test = X_test.astype('float32')
X_train /= 255
X_test /=255
Y_train = np_utils.to_categorical(y_train, nb_classes)
Y_test = np_utils.to_categorical(y_test, nb_classes)
                        </code></pre>
                    </section>

                    <section>
                        <h2>Creating The Model</h2>
                        <pre><code class="python" data-trim contenteditable>
from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation, Flatten
from keras.layers import Convolution2D, MaxPooling2D

kernel_size = (3,3)

model = Sequential()

model.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1],
                        border_mode = 'valid',
                        input_shape=input_shape))

                        </code></pre>
                    </section>

                    <section>
                        <pre><code class="python" data-trim contenteditable>
model.add(Activation('relu'))
model.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1]))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=pool_size))
model.add(Dropout(0.25))

model.add(Flatten())
model.add(Dense(128))
model.add(Activation('relu'))
model.add(Dropout(0.5))
model.add(Dense(nb_classes))
model.add(Activation('softmax'))
                        </code></pre>
                    </section>

                    <section>
                        <h2>Training</h2>
                        <pre><code class="python" data-trim contenteditable>
model.compile(loss='categorical_crossentropy',
              optimizer='adadelta',
              metrics=['accuracy'])


model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,
          verbose=1, validation_data=(X_test, Y_test))
                        </code></pre>
                    </section>

                    <section>
                        <h2>Testing</h2>
                        <pre><code class="python" data-trim contenteditable>
score = model.evaluate(X_test, Y_test, verbose=0)
                        </code></pre>
                    </section>
                </section>

                <!-- Further Reading and References -->
                <section>
                    <section>
                        <h2>Further Reading and References</h2> 
                    </section>

                    <section style="text-align: left">
                        <h2 style="text-align: center;">Citations</h2>
                        <p>1) Bengio, Y. and LeCun, Y. (2007). Scaling learning algorithms towards AI. In Large Scale Kernel Machines.</p>
                        <p>2) He, Kaiming, et al. "Deep residual learning for image recognition." arXiv preprint arXiv:1512.03385 (2015).</p>
                    </section>

                    <section style="text-align: left">
                        <h2>Convolutional Neural Network Reading</h2>
                        <ol>
                            <li><a href="http://colah.github.io/posts/2014-07-Understanding-Convolutions/">Christopher Olah Blog Post</a></li>
                            <li><a href="yann.lecun.com/exdb/publis/pdf/lecun-98.pdf">LeNet, one of the first CNNs</a></li>
                            <li><a href="http://papers.nips.cc/paper/4824-imagenet-classification-w">AlexNet, one of the first deep CNNs</a></li>
                        </ol>
                    </section>

                    <section>
                        <h2>Recurrent Neural Network Reading</h2>
                        <ol>
                            <li><a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/">Andrej Karpathy Recurrent Neural Network</a></li>
                            <li><a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/">Christopher Olah Blog Post</a></li>
                            <li><a href="http://ieeexplore.ieee.org/document/6795963/">LSTM Paper</a></li>
                        </ol>
                    </section>

                    <section>
                        <h2>Hyperparameter Reading</h2>
                        <ol>
                            <li><a href="http://link.springer.com/chapter/10.1007/978-3-642-35289-8_26">Hyperparameter Recommendations</a></li>
                            <li><a href="http://www.jmlr.org/proceedings/papers/v28/sutskever13.pdf">On the importance of initializations</a></li>
                            <li><a href="http://www.jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf?hc_location=ufi">Xavier Initialization</a></li>
                            <li><a href="http://www.cv-foundation.org/openaccess/content_iccv_2015/html/He_Delving_Deep_into_ICCV_2015_paper.html">He Initialization</a></li>
                        </ol>
                    </section>

                    <section>
                        <h2>Miscellaneous</h2>
                        <ol>
                            <li><a href="http://www.jmlr.org/papers/volume15/srivastava14a.old/source/srivastava14a.pdf">Dropout</a></li>
                            <li><a href="http://papers.nips.cc/paper/5346-information-based-learning-by-agents-in-unbounded-state-spaces">Sequence to Sequence Learning</a></li>
                        </ol>
                    </section>
                </section>

                <!-- Questions -->
                <section>
                    <h2>Questions?</h2>
                    <ul>
                        <li><a href="#/1">Demos</a></li>
                        <li><a href="#/3">What is it?</a></li>
                        <li><a href="#/4">Why use it?</a></li>
                        <li><a href="#/5">How to use it?</a></li>
                        <li><a href="#/6">Where to start?</a></li>
                        <li><a href="#/7">Coding Demo</a></li>
                    </ul>
                </section>

                <!-- Slides div -->
		</div>

                <!-- Reveal div -->
		</div>

		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.js"></script>

		<script>

			// More info https://github.com/hakimel/reveal.js#configuration
			Reveal.initialize({
				controls: true,
				progress: true,
				history: true,
				center: true,

				transition: 'concave', // none/fade/slide/convex/concave/zoom

				// More info https://github.com/hakimel/reveal.js#dependencies
				dependencies: [
					{ src: 'lib/js/classList.js', condition: function() { return !document.body.classList; } },
					{ src: 'plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
					{ src: 'plugin/zoom-js/zoom.js', async: true },
					{ src: 'plugin/notes/notes.js', async: true }
				]
			});

		</script>

	</body>
</html>
